{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "In this notebook we will explain briefly the most used supervised learning algorithms for both classificaiton and regression and we will apply them to a real datasets and compare the performances. We will use the Python package [SKLearn](https://scikit-learn.org/) that implements a lot of machine learning algorithms.\n",
    "Before comparing the models on the selected dataset let us introduce a fundamental concept that will help us understand better the concepts of overfitting, underfitting and the regularization techniques: the bias-variance decomposition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Decomposition\n",
    "The error of an estimator (that in our case is the Machine Learning model) can be decomposed into two terms: a bias term and a variance term. Imagine we could train the same model on many different datasets. The bias tells how much is the error if we take the average of the predictions from these models, while the variance term is the variance of predictions obtained by these models. Matematically \n",
    "$$\n",
    "Err(x) = \\mathbb{E}_{\\hat{f}}[(\\mathbb{E}_{\\hat{f}}[\\hat{f}(x)]-f(x))^2] + \\mathbb{E}_{\\hat{f}}[(\\hat{f}(x)-\\mathbb{E}_{\\hat{f}}[\\hat{f}(x)])^2]\n",
    "$$\n",
    "Where $\\hat{f}$ is the predicted function and $f$ is the true function. Note the expectation over the models trained on different datasets.\n",
    "Bias and variance are represented in the following image, borrowed from this [great article](http://scott.fortmann-roe.com/docs/BiasVariance.html) on bias-variance decomposition:\n",
    "<p align=\"center\">\n",
    "  <img src=\"../imgs/biasvariance.png\"/ width=30%>\n",
    "</p>\n",
    "As we can see from the picture, an estimator with high bias and low variance will return on average a value that is different from the true value, but the predicted values will be similar. While an estimator with low bias and high variance will return the correct value on average, but the predicted values will change a lot. \n",
    "The bias variance decomposition is a different way to express the concepts of overfitting and underfitting. If we increase the model capacity we reduce the bias but we might increase variance and vice versa. As shown by the figure:\n",
    "<p align=\"center\">\n",
    "  <img src=\"../imgs/overunderfitting.png\"/ width=30%>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "For the regression tasks we will use the Diabetes dataset represents patients in a 10-dimensional feature space, where the features represent:\n",
    "- age age in years\n",
    "- sex\n",
    "- bmi body mass index\n",
    "- bp average blood pressure\n",
    "- s1 tc, total serum cholesterol\n",
    "- s2 ldl, low-density lipoproteins\n",
    "- s3 hdl, high-density lipoproteins\n",
    "- s4 tch, total cholesterol / HDL\n",
    "- s5 ltg, possibly log of serum triglycerides level\n",
    "- s6 glu, blood sugar level\n",
    "\n",
    "The feature variables are mean centered and scaled by the standard deviation times the square root of n_samples.\n",
    "The targets $Y$ are integers in the range $[25,346]$ and are a quantitative measure of disease progression one year after the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10),(442,)\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_diabetes(return_X_y=True)\n",
    "print(f\"{X.shape},{Y.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 90% of the data for training and 10% for testing. First we shuffle the data so that we can assume that data are not ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 10),(397,)\n",
      "(45, 10),(45,)\n"
     ]
    }
   ],
   "source": [
    "X,Y = sklearn.utils.shuffle(X,Y,random_state=9)\n",
    "\n",
    "X_train = X[0:int(0.9 * X.shape[0])]\n",
    "Y_train = Y[0:int(0.9 * X.shape[0])]\n",
    "X_test  = X[int(0.9 * X.shape[0]):]\n",
    "Y_test  = Y[int(0.9 * X.shape[0]):]\n",
    "\n",
    "print(f\"{X_train.shape},{Y_train.shape}\")\n",
    "print(f\"{X_test.shape},{Y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "Each estimators in sklearn have a score method providing a default evaluation criterion for the problem they are designed to solve. From the documentation we read that the score method of the KNeighborsClassifier returns the coefficient of determination. that is defined as $(1-\\frac{u}{v})$, where $u$ is the residual sum of squares `((y_true - y_pred)** 2).sum()` and $v$ is the total sum of squares `((y_true - y_true.mean()) ** 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \n",
    "score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (Trainset): 0.17884130982367757\n",
      "Coefficient of determination (Testset): 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train,Y_train)\n",
    "print(f\"Coefficient of determination (Trainset): {model.score(X_train,Y_train)}\")\n",
    "print(f\"Coefficient of determination (Testset): {model.score(X_test,Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some predictions on the Testset:\n",
      "\t\tY_true:[138.  91.  99. 170. 317. 281. 142. 144. 155. 280.] \n",
      "\t\tY_pred:[144. 171. 220.  87. 192. 109. 107.  25. 150. 195.]\n",
      "Some predictions on the Trainset:\n",
      "\t\tY_true:[104. 118. 186. 132. 199. 215. 279. 135.  65.  70.],\n",
      "\t\tY_pred:[ 55.  65. 186.  44.  71.  67. 109.  50.  65.  71.]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(f\"Some predictions on the Testset:\\n\\t\\tY_true:{Y_test[0:10]} \\n\\t\\tY_pred:{Y_pred[0:10]}\")\n",
    "Y_pred = model.predict(X_train)\n",
    "print(f\"Some predictions on the Trainset:\\n\\t\\tY_true:{Y_train[0:10]},\\n\\t\\tY_pred:{Y_pred[0:10]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "This is the standard Linear regression we implemented from scratch in the previous lecture. The minimization objective is:\n",
    "$$\n",
    "|| \\mathbf{y} - \\mathbb{X} \\mathbf{w} ||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (Trainset): 0.5413921609396912\n",
      "Coefficient of determination (Testset): 0.29612044394293746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "print(f\"Coefficient of determination (Trainset): {model.score(X_train,Y_train)}\")\n",
    "print(f\"Coefficient of determination (Testset): {model.score(X_test,Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some predictions on the Testset:\n",
      "\t\tY_true:[138  91  99 170 317 281 142 144 155 280] \n",
      "\t\tY_pred:[171 150 231  90 224 196 190 124 219 235]\n",
      "Some predictions on the Trainset:\n",
      "\t\tY_true:[104 118 186 132 199 215 279 135  65  70],\n",
      "\t\tY_pred:[ 75  96 202 121 111 248 216 126 122  62]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(f\"Some predictions on the Testset:\\n\\t\\tY_true:{Y_test[0:10].astype(np.int32)} \\n\\t\\tY_pred:{Y_pred[0:10].astype(np.int32)}\")\n",
    "Y_pred = model.predict(X_train)\n",
    "print(f\"Some predictions on the Trainset:\\n\\t\\tY_true:{Y_train[0:10].astype(np.int32)},\\n\\t\\tY_pred:{Y_pred[0:10].astype(np.int32)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "Regularization is an indictive bias that results in favoring some hypotheses over others. The most used regularization techniques are:\n",
    "- __L1 regularization__ where the L1 norm of the parameters:\n",
    "$$\n",
    "L1(w\\in \\mathbb{R}^d) = \\sum_i^d |w_i|\n",
    "$$\n",
    "is minimized together with the objective. The linear regression with L1 regularization is called Lasso Regression.\n",
    "- __L2 regularization__ where the L2 norm of the parameters:\n",
    "$$\n",
    "L2(w\\in \\mathbb{R}^d) = \\sqrt{\\sum_i^d w_i^2}\n",
    "$$\n",
    "is minimized together with the objective. The linear regression with L2 regularization is called Ridge Regression.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (Trainset): 0.382943118645549\n",
      "Coefficient of determination (Testset): 0.21692207839766886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=1.)\n",
    "model.fit(X_train,Y_train)\n",
    "print(f\"Coefficient of determination (Trainset): {model.score(X_train,Y_train)}\")\n",
    "print(f\"Coefficient of determination (Testset): {model.score(X_test,Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some predictions on the Testset:\n",
      "\t\tY_true:[138  91  99 170 317 281 142 144 155 280] \n",
      "\t\tY_pred:[158 140 189 125 184 164 168 130 167 177]\n",
      "Some predictions on the Trainset:\n",
      "\t\tY_true:[104 118 186 132 199 215 279 135  65  70],\n",
      "\t\tY_pred:[111 127 187 131 128 197 188 127 135 103]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(f\"Some predictions on the Testset:\\n\\t\\tY_true:{Y_test[0:10].astype(np.int32)} \\n\\t\\tY_pred:{Y_pred[0:10].astype(np.int32)}\")\n",
    "Y_pred = model.predict(X_train)\n",
    "print(f\"Some predictions on the Trainset:\\n\\t\\tY_true:{Y_train[0:10].astype(np.int32)},\\n\\t\\tY_pred:{Y_pred[0:10].astype(np.int32)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (Trainset): 0.4613537648625582\n",
      "Coefficient of determination (Testset): 0.32552492063229144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=1)\n",
    "model.fit(X_train,Y_train)\n",
    "print(f\"Coefficient of determination (Trainset): {model.score(X_train,Y_train)}\")\n",
    "print(f\"Coefficient of determination (Testset): {model.score(X_test,Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some predictions on the Testset:\n",
      "\t\tY_true:[138  91  99 170 317 281 142 144 155 280] \n",
      "\t\tY_pred:[178 163 185 102 210 174 177 124 201 193]\n",
      "Some predictions on the Trainset:\n",
      "\t\tY_true:[104 118 186 132 199 215 279 135  65  70],\n",
      "\t\tY_pred:[100 130 193 140 131 208 193 133 143  89]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(f\"Some predictions on the Testset:\\n\\t\\tY_true:{Y_test[0:10].astype(np.int32)} \\n\\t\\tY_pred:{Y_pred[0:10].astype(np.int32)}\")\n",
    "Y_pred = model.predict(X_train)\n",
    "print(f\"Some predictions on the Trainset:\\n\\t\\tY_true:{Y_train[0:10].astype(np.int32)},\\n\\t\\tY_pred:{Y_pred[0:10].astype(np.int32)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
